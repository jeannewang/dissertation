
\chapter{Engineering Details}
\paragraph{}
In this chapter, I will describe in more detail important engineering tasks necessary to build the HLBL model, described in Section \ref{sec:proposedModel}. These tasks include initializing the model, building binary trees, checking the finite gradient and also caching key parameters.

\paragraph{}
My implementation of the HLBL model is an extension of the C++ LBL implementation by Phil Blunsom. Additionally, I use tree.hh: an STL-like C++ tree library written by Kasper Peeters, and the Boost \cite{BoostSite} and Eigen \cite{eigenweb} libraries. The full implementation can be found online at \url{https://github.com/jeannewang/oxlm}. Much of the code can be found in Appendix C.

\section{Model Initialization}
\paragraph{}
All of the model parameters ($Q,R,$ and $C_i$ for all context positions) except for the $B$ vector are initialized using Gaussian distributions with mean $0$, and variance $0.1$.
\subsection{$B$ Initialization}
\paragraph{}
Intelligent initialization of the bias matrix can improve perplexity measures. The $B$ vector contains a bias for each node in the binary tree.  The $B$ vector should be initialized with the unigram distribution of the training data. As a bias $b_j$ does not directly correlate to an individual word, $b_j$ should be initialized to the sum of the unigram probability of all words in the subtree under node $j$.  I compared initialization with a Gaussian distribution to unigram initialization and found a $50\times$ improvement in initial perplexity measures. If the model's initial perplexity is low, then few training iterations are generally needed. A poor initial perplexity often negatively affects the perplexity of the fully trained model.

\section{Building Trees}
\paragraph{}
I have described the algorithms to build specific trees in Section \ref{sec:treeCreation}, but I will describe here some additional tips for building trees. I use simple integer trees for my binary trees. My trees contain indices into the $Q$ matrix for the internal node values, and indices into the $R$ matrix for the leaf values. The indices into the $R$ matrix are also the word indices. To tell if I am looking at a word, or a node, I check if the node is a leaf node or not.  I found building binary trees for vocabularies to be easier going bottom-up than top-down. This is because one can group together "similar" words more easily by going from the words to the nodes, than the other way around. I also found that the easiest way to keep track of indices to the $Q$ matrix is by storing the indices in the tree. It makes no difference which $Q$ node is assigned to which $Q$ index so long as it is consistent. I assign $Q$ indices sequentially breadth-first though the tree. 
\paragraph{}
When reading in trees from binary codes, it is necessary to build the tree top-down. To build the tree, I read in every code, and for each digit in the code, add in a node if necessary. If a new code has a branch that does not exist in the tree, I create it, and continue parsing the code.

\subsection{Mixture of Gaussians for ADAPTIVE trees}
\paragraph{}
A \emph{Gaussian Mixture Model} (GMM) is used to cluster word representations in the ADAPTIVE and Recursive ADAPTIVE trees described in Section \ref{sec:recursiveADAPTIVETree}. To initialize the parameters for the GMM, I randomly assign the word representations into two groups, and then calculate the group means and covariances to initialize $\mu_k$ and $\sigma_k$. The mixing coefficients $\pi_k$ are initialized to the uniform distribution. Also, when calculating the Gaussian, I find it much faster to use diagonalized covariance matrices. While this does lose some representational power of the covariance matrices, I find the speedup to be worth it. I run each GMM until convergence, or for 10 epochs, whichever is less. If any of the parameters become ill-defined, I back off to the previous epoch's values. 

\section{Finite Gradient Check}
\paragraph{}
An easy place to mess up the HLBL implementation is in the gradient computation. One simple way to check if the gradients are being calculated correctly is to use a finite gradient check. The finite gradient check uses the mathematical definition of the derivative. I am going to use the central difference definition, though the forward and backward differences can also be used. The derivative for each parameter value is given by:
\begin{align}
\frac{d}{d\theta} J(\theta) = \lim_{\epsilon \to 0} \frac{ J({\theta + \epsilon} )- J({\theta - \epsilon}) } {2 \epsilon}
\end{align}
We see that the derivative is given in the limit of $\epsilon \to 0$, therefore if we set $\epsilon$ to a small number ($\approx10^4$), we can approximate the derivative of the objective function. The finite gradient check can then be compared with the gradients calculated from Equations \ref{eq:gradients} on the training data. The finite gradient check is computationally slow, and so should only be used as a check and not as the final gradient computation.

\section{Caching}
\paragraph{}
Certain variables should be cached as they are used multiples times while calculating portions of the objective function, the gradients or the perplexity. It is important to cache these values as caching can reduce the training time by avoiding recomputing computationally-expensive values. The values that should be cached include: $\hat{r}$, and $C_i^T q_j$. The $\hat{r}$ term is particularly important to cache as it is used in the calculation of the objective function, all of the gradients, and the perplexity. Note that a separate $\hat{r}$ should be cached for training versus testing data.

